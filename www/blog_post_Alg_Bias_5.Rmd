---
title: 'DIY trust scores'
---
By Sarah Gillespie
 
Published January 17, 2022

### Why use trust scores?

### Who invented these trust scores?

Trust scores are introduced in the [To Trust Or Not To Trust A Classifier](https://arxiv.org/pdf/1805.11783.pdf), presented at Neural Information Processing Systems in 2018. The trust scores are a similar concept to the credibility and confidence scores introduced in [Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning](https://arxiv.org/pdf/1803.04765.pdf). The trust score is a remarkably flexible ratio with a purpose of describing how much a user should trust an algorithm's classification of a specific point. The trust score has two steps: first, remove the outlying points, and second, calculate the ratio of the distance from the testing sample to the nearest classes similar and class different from the testing sample. This trust score for a testing sample is likely agree with the Bayes-optimal classifier, so the trust score is a clue to decide if an algorithm's prediction about a test point is correct rather than a Type I or II Error. This approach mixes the topology of points in a multidimensional space with calculus to be effective at detecting the accuracy of a unique machine learning prediction.


### Code to calculate trust scores yourself:

### How to interpret the scores

If trust score > 1, then the different class is geographically closer to the testing sample than its predicted class. This is a red flag for the testing sample's categorization being incorrect.

### References

The code for the [To Trust Or Not To Trust A Classifier](https://arxiv.org/pdf/1805.11783.pdf) paper is located on [Github](https://github.com/google/TrustScore) and has been updated for Python 3.
