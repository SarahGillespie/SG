---
title: 'DIY trust scores'
---
By Sarah Gillespie
 
Published February 13, 2022

### What are trust scores?


The trust scores approach mixes the topology of points in a multidimensional space with calculus to be effective at detecting the accuracy of a unique machine learning prediction. Each unique prediction has its own unique trust score. This concept was introduced in the [To Trust Or Not To Trust A Classifier](https://arxiv.org/pdf/1805.11783.pdf), presented at Neural Information Processing Systems in 2018. The trust score is a remarkably flexible ratio with a purpose of describing how much a user should trust an algorithm's classification of a specific point. Creating a trust score has two steps: first, remove the outlying points, and second, calculate the ratio of the distance from the testing sample to the nearest classes similar and nearest class different from the testing sample. The trust score for a testing sample is likely to agree with the point's Bayes-optimal classifier. This means the trust score is a clue to decide if an algorithm's prediction about a test point is correct, rather than a Type I or II Error. 


### Code to calculate trust scores yourself:

While the initial trust score code was done in Python 2.7, it was updated to be usable in Python 3. I have adapted the given Python code to work in R and R Studio by using the reticulate package, a comprehensive set of tools for interoperability between Python and R.


#### Step 1: Gather materials.
Download the entire repository. It is especially important for you to have the trustscores.py in the same folder as your .Rmd file to import the trust score functions that are in that Python file.

#### Step 2: Open R Studio and work though the following lines of code.

The code in this tutorial creates trust scores based on penguin species type predictions with data from the Palmer Penguins package. I tried to make this code as generalized as possible for you to easily swap in your own data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)

```


```{r libraries}
# R code chunk
# Load the R libraries
library(palmerpenguins) # bring in data about penguin species
library(dplyr) # tools for data wrangling in R
library(reticulate) # provides a comprehensive set of tools for interoperability 
                    # between Python and R.

```


```{r configure python}
# R code chunk
# configure Python
reticulate::py_config() # Double check that reticulate is actually using your 
                        # new conda environment.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn
                                              # wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::py_install("pandas")

# setting up the Python environment and bringing in the required Python packages 
# is important.
# Running this code will likely take 5 to 10 minutes if you do not already have
# these Python packages installed. Otherwise, 

# common trouble shooting:
# if you're missing a package, try adding its name in an additional argument of 
# py_install . if py_install isn't working then try adding the pip = TRUE
# argument to try installing the library through pip rather than anaconda.
```

```{python}
# Python code chunk

# import required Python packages
import numpy as np
import trustscore # you need to have trustscore.py file in the same folder as 
                  # this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the 
                              # same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras
import pandas as pd



```

There might be some scary errors about "dlerror: cudart64_110.dll not found". It's just a warning and you can ignore it.

```{r data wrangling}
# R code chunk

# data
penguins_df <- penguins %>%
    dplyr::filter(complete.cases(.))
# remove all lines with missing values so the model can fit the data
 
penguins_data <- penguins_df %>%
  dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)

# target: species
penguins_target <- penguins_df %>%
  dplyr::select(species)
  
  
```


```{python import data from R}
# Python code chunk
# Import penguins from R into Python
penguins_data = r.penguins_data

penguins_target = r.penguins_target
```

```{python encode species to be numbers}
# Python code chunk

# Python function: encode each penguin species to be a number.
# purpose: make it easier for the model to assign a species prediction and its trust score

dictionary = {}
current_index = 0

def encode(value):
    if value in dictionary:
      return dictionary[value]
    else:
      global current_index
      
      new_index = current_index
      dictionary[value] = new_index
      current_index = current_index + 1
      
      return new_index

X_penguins = penguins_data

y_penguins = list(map(encode, penguins_target.values.ravel()))
# at this point y_penguins is a list. We will need to make it a numpy array later.

# dictionary coordinating each penguin species connected to its assigned number
print(dictionary)
```

## Logistic Regression

```{python logistic regression model}
# Python code chunk

# you may want to run each of these one line at a time in the console.

# import the model
from sklearn.linear_model import LogisticRegression

# Train logistic regression on digits.
model = LogisticRegression()

# fit the model
model.fit(X_penguins, y_penguins)

# Implement the model / create outputs on testing set.
y_pred = model.predict(X_penguins)
```

You may get a "failed to converge" and "max number of iterations reached" warning. This is about the data not fitting well to the assigned model rather than a tech issue. This warning can safely be ignored.

```{python compute the trust scores}
# Python code chunk

# Initialize trust score.
trust_model = trustscore.TrustScore()

# convert the inputs into numpy arrays
X_penguins = X_penguins.to_numpy()
y_penguins = np.array(y_penguins)

# fit the trust scores model
trust_model.fit(X_penguins, y_penguins)

# the model will be fitted. It produces no output.
```

```{python}
# Python code chunk

# Compute trusts score from the above model, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_penguins, y_pred)

# prints the trust scores for each point in the inputted data set
print(trust_score)

```

#### Further Steps:
Consider the other model options:

from sklearn.svm import LinearSVC

from sklearn.ensemble import RandomForestClassifier

Additionally, consider alternate scores to consider the trustability of your model's output. One intuitive but less rigoriously researched scoring system is confidence and credibility scores.

### How to interpret the scores

If trust score > 1, then the different class is geographically closer to the testing sample than its predicted class. This is a red flag for the testing sample's categorization being incorrect.

### References

The code for the [To Trust Or Not To Trust A Classifier](https://arxiv.org/pdf/1805.11783.pdf) paper is located on [Github](https://github.com/google/TrustScore) and has been updated for Python 3.
